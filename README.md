# README ‚Äî Modelo de Detec√ß√£o de Fraudes em Transa√ß√µes de Cart√£o de Cr√©dito üí≥

O objetivo deste projeto √© desenvolver um M√≠nimo Produto Vi√°vel (MVP) de um sistema de detec√ß√£o autom√°tica de fraudes em transa√ß√µes financeiras, utilizando t√©cnicas de aprendizado de m√°quina supervisionado. A tarefa consiste em analisar um grande volume de transa√ß√µes de cart√£o de cr√©dito, identificar padr√µes de comportamento e classificar automaticamente cada transa√ß√£o como ‚Äúfraude‚Äù ou ‚Äún√£o fraude‚Äù.

Por se tratar de um problema real e cr√≠tico, a base apresenta forte desbalanceamento de classes, exigindo estrat√©gias espec√≠ficas para evitar m√©tricas enganosas e melhorar a sensibilidade do modelo.

üß† Hip√≥tese
As transa√ß√µes fraudulentas apresentam padr√µes estat√≠sticos e num√©ricos diferentes das transa√ß√µes leg√≠timas, permitindo que algoritmos supervisionados aprendam a distinguir esses dois grupos com alta capacidade de generaliza√ß√£o.

A hip√≥tese central √© de que, com a combina√ß√£o de: m√©tricas adequadas (como F1 e ROC-AUC), balanceamento dos dados (SMOTE) e ajuste do threshold de decis√£o, √© poss√≠vel obter um modelo com alto recall para a classe minorit√°ria, sem comprometer a precis√£o de forma significativa.

## 1) Configura√ß√£o Inicial e Instala√ß√£o de Pacotes
Nesta etapa foram instaladas e importadas todas as bibliotecas necess√°rias:

* kaggle ‚Äî para download automatizado do dataset
* pandas/numpy/seaborn/matplotlib ‚Äî para manipula√ß√£o e an√°lise explorat√≥ria
* scikit-learn ‚Äî para modelagem e m√©tricas
* imbalanced-learn ‚Äî para balanceamento com SMOTE.

```python
!pip -q install kaggle imbalanced-learn

import os, json, pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, recall_score, f1_score, roc_auc_score,
                             classification_report, confusion_matrix, roc_curve, auc,
                             precision_recall_curve)
from imblearn.over_sampling import SMOTE
import joblib
```

## 2) üì• Download do Dataset via Kaggle

As credenciais da conta Kaggle foram configuradas diretamente no ambiente Colab, e o dataset foi baixado e descompactado automaticamente.
O arquivo CSV foi lido com pandas e apresentou 284.807 linhas e 31 colunas, sem valores ausentes.

```python
DATASET_SLUG = "mlg-ulb/creditcardfraud"
df = pd.read_csv("creditcard.csv")
print(df.shape)
```

## 3) üìä An√°lise Explorat√≥ria dos Dados (EDA)
A etapa inicial de an√°lise explorat√≥ria de dados (EDA) teve como objetivo compreender a estrutura e as principais caracter√≠sticas do dataset antes da etapa de modelagem. Primeiramente, verificou-se que n√£o havia valores ausentes em nenhuma das 31 colunas, o que eliminou a necessidade de estrat√©gias de imputa√ß√£o ou limpeza complexa. Al√©m disso, observou-se que as vari√°veis V1 a V28 j√° se encontram padronizadas, resultado de uma transforma√ß√£o pr√©via por An√°lise de Componentes Principais (PCA), t√©cnica comumente utilizada para anonimizar dados de cart√£o de cr√©dito e, ao mesmo tempo, reduzir dimensionalidade preservando informa√ß√µes relevantes para detec√ß√£o de padr√µes.

Outro ponto importante foi a an√°lise da vari√°vel Amount (valor da transa√ß√£o), cuja distribui√ß√£o mostrou-se fortemente assim√©trica, concentrando a maioria dos valores pr√≥ximos de zero e alguns poucos valores muito altos. Para suavizar essa assimetria e permitir uma melhor visualiza√ß√£o e tratamento estat√≠stico, foi aplicada uma transforma√ß√£o logar√≠tmica log(Amount + 1), o que resultou em uma distribui√ß√£o mais equilibrada e informativa para o modelo.

Al√©m disso, constatou-se que a vari√°vel alvo Class apresenta um desbalanceamento extremo, com aproximadamente 99,83% das transa√ß√µes rotuladas como ‚Äún√£o fraude‚Äù e apenas 0,17% como ‚Äúfraude‚Äù. Essa caracter√≠stica impacta diretamente o desempenho dos modelos de classifica√ß√£o, exigindo a ado√ß√£o de estrat√©gias espec√≠ficas de balanceamento e m√©tricas adequadas, como o F1-score e o ROC-AUC, para avaliar corretamente a performance.

Para apoiar essas conclus√µes, foram gerados gr√°ficos explorat√≥rios fundamentais: um histograma dos valores originais de Amount, um histograma da distribui√ß√£o log-transformada e uma matriz de correla√ß√£o para investigar a rela√ß√£o entre as vari√°veis. Embora as vari√°veis PCA apresentem correla√ß√µes baixas e bem distribu√≠das, a an√°lise visual foi essencial para confirmar a aus√™ncia de colinearidade excessiva e orientar as etapas de pr√©-processamento e modelagem.

## 4) ‚úÇÔ∏è Divis√£o Treino/Teste (Stratified)

Os dados foram divididos em 80% treino e 20% teste, preservando a propor√ß√£o das classes (stratify=y). Isso garante representatividade da classe fraudulenta em ambos os conjuntos.

## 5) üß™ Modelagem Inicial ‚Äî Baseline, Logistic Regression e Random Forest

Baseline com DummyClassifier:
* Accuracy ‚âà 0.998
* Recall = 0 (n√£o detectou nenhuma fraude).

Logistic Regression (com class_weight='balanced'):
* Recall alto, por√©m precis√£o baixa.

Random Forest:
* Melhor equil√≠brio entre precis√£o e recall.
* F1-score muito superior ao baseline.
Essa etapa foi importante para estabelecer um ponto de compara√ß√£o inicial.

## 6) üìà Verifica√ß√£o de Overfitting e Underfitting
As acur√°cias no treino e teste foram praticamente iguais para Random Forest, indicando boa generaliza√ß√£o.
```python
Acur√°cia Treino: 1.0000  
Acur√°cia Teste:  0.9995
```

##7) üîπ Valida√ß√£o Cruzada (3 folds)
Foi aplicada valida√ß√£o cruzada estratificada com 3 folds para avaliar a consist√™ncia das m√©tricas entre diferentes parti√ß√µes do conjunto de dados. Essa t√©cnica reduz o risco de overfitting e garante maior confiabilidade nos resultados obtidos.

Os testes mostraram que a Regress√£o Log√≠stica apresentou um F1 m√©dio consideravelmente baixo, evidenciando dificuldade em capturar padr√µes da classe minorit√°ria. Por outro lado, o Random Forest apresentou F1 m√©dio consistente e desvio padr√£o pequeno, demonstrando boa capacidade de generaliza√ß√£o e robustez.
```python
from sklearn.model_selection import StratifiedKFold, cross_val_score

cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
scores_log = cross_val_score(pipe_log, X_train, y_train, cv=cv, scoring='f1')
scores_rf = cross_val_score(pipe_rf, X_train, y_train, cv=cv, scoring='f1')
```

Em seguida, foi realizada a etapa de ajuste de hiperpar√¢metros por meio do GridSearchCV, utilizando tamb√©m valida√ß√£o cruzada. O objetivo foi buscar a melhor combina√ß√£o entre os par√¢metros n_estimators (50 e 100) e max_depth (10 e None). Essa etapa permitiu encontrar um modelo Random Forest otimizado, que manteve alto desempenho no conjunto de teste, equilibrando capacidade de detec√ß√£o de fraudes e generaliza√ß√£o.
```python
param_grid = {
    'clf__n_estimators': [50, 100],
    'clf__max_depth': [10, None]
}

grid = GridSearchCV(pipe_rf, param_grid=param_grid, cv=3, scoring='f1', n_jobs=-1)
grid.fit(X_train_sample, y_train_sample)
best_model = grid.best_estimator_
```

Ap√≥s a otimiza√ß√£o, foi feita a avalia√ß√£o detalhada do modelo ajustado. As m√©tricas de desempenho mostraram Acur√°cia ‚âà 0.9990, F1-score ‚âà 0.6093 e ROC-AUC ‚âà 0.9428, valores bastante altos, mas ainda com espa√ßo para melhoria no recall da classe minorit√°ria. Foram geradas duas visualiza√ß√µes essenciais para interpreta√ß√£o do modelo: a matriz de confus√£o, que evidencia a propor√ß√£o de acertos e erros entre as classes, e a curva ROC, que ilustra a rela√ß√£o entre taxa de verdadeiros positivos e falsos positivos.

Para lidar mais diretamente com o forte desbalanceamento da vari√°vel alvo, foi introduzida a primeira estrat√©gia de melhoria: rebalanceamento com SMOTE (Synthetic Minority Over-sampling Technique). Essa t√©cnica gera novas amostras sint√©ticas da classe minorit√°ria, equilibrando a distribui√ß√£o de classes no conjunto de treino.
```python
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)
```

O modelo Random Forest reentreinado ap√≥s SMOTE apresentou um aumento expressivo no F1-score e no recall, confirmando a efetividade da t√©cnica para melhorar a sensibilidade na detec√ß√£o de fraudes.

A segunda melhoria aplicada foi o ajuste do limiar de decis√£o (threshold). O threshold padr√£o de 0.5 foi substitu√≠do por um valor √≥timo determinado a partir da maximiza√ß√£o do F1-score na curva Precision-Recall, permitindo um controle mais fino sobre a taxa de verdadeiros positivos e falsos positivos.
Essa abordagem aumentou significativamente a sensibilidade do modelo, reduzindo falsos negativos e melhorando o equil√≠brio entre precis√£o e recall ‚Äî dois indicadores cr√≠ticos em problemas de detec√ß√£o de fraude.

Com todas as etapas implementadas, foi realizada uma compara√ß√£o consolidada entre modelos. Os resultados mostram claramente que a acur√°cia isolada √© enganosa, j√° que mesmo um classificador que s√≥ prediz a classe majorit√°ria apresenta alta acur√°cia. M√©tricas mais sens√≠veis ao desbalanceamento, como F1-score e ROC-AUC, mostraram que as estrat√©gias de SMOTE e threshold tuning foram determinantes para melhorar o desempenho do modelo, especialmente na classe minorit√°ria.

A an√°lise do desbalanceamento foi complementada com um gr√°fico de barras, que ilustrou visualmente a disparidade extrema entre as classes ‚ÄúN√£o Fraude‚Äù e ‚ÄúFraude‚Äù. Essa etapa refor√ßou a import√¢ncia das t√©cnicas de balanceamento aplicadas para que o modelo conseguisse aprender padr√µes da minoria de forma eficaz.

O resumo t√©cnico final consolida os principais pontos do projeto:
* O dataset apresentou alto desbalanceamento entre classes;
* Foram utilizadas m√©tricas adequadas ao contexto: F1-score e ROC-AUC;
* T√©cnicas aplicadas: valida√ß√£o cruzada, GridSearchCV, SMOTE e ajuste de threshold;

O melhor modelo encontrado foi um Random Forest otimizado com t√©cnicas de balanceamento, que obteve desempenho robusto na classe de fraude sem apresentar sinais relevantes de overfitting.

Por fim, o modelo final foi salvo em arquivo .pkl para uso posterior ou integra√ß√£o em um pipeline de produ√ß√£o:
```python
import joblib
joblib.dump(best_model, 'best_model_creditcard_rf.pkl')
```

Como pr√≥ximos passos recomendados, sugere-se explorar modelos mais avan√ßados, como XGBoost e LightGBM, realizar calibra√ß√£o de probabilidades para melhor interpreta√ß√£o dos scores, implementar monitoramento de drift e explicabilidade (por exemplo, com SHAP ou LIME) e, futuramente, desenvolver um dashboard em tempo real para acompanhamento cont√≠nuo da performance do modelo em produ√ß√£o.




