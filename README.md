# README ‚Äî Modelo de Detec√ß√£o de Fraudes em Transa√ß√µes de Cart√£o de Cr√©dito üí≥

O objetivo deste projeto √© desenvolver um M√≠nimo Produto Vi√°vel (MVP) para um sistema de detec√ß√£o autom√°tica de fraudes em transa√ß√µes financeiras, utilizando t√©cnicas de aprendizado de m√°quina supervisionado. A proposta consiste em analisar um grande volume de transa√ß√µes com cart√£o de cr√©dito, identificar padr√µes comportamentais e classificar automaticamente cada opera√ß√£o como ‚Äúfraude‚Äù ou ‚Äún√£o fraude‚Äù.

Por se tratar de um problema real e de alta criticidade, a base de dados apresenta forte desbalanceamento de classes, o que demanda estrat√©gias adequadas para evitar m√©tricas ilus√≥rias e garantir maior sensibilidade na detec√ß√£o de fraudes.

O projeto utiliza o dataset p√∫blico Credit Card Fraud Detection, disponibilizado no Kaggle, escolhido com base em tr√™s fatores principais:

* Relev√¢ncia pr√°tica: a detec√ß√£o de fraudes em cart√µes de cr√©dito √© um dos problemas mais cl√°ssicos e cr√≠ticos no uso de machine learning, com impacto direto na seguran√ßa financeira.
* Desafios t√©cnicos: trata-se de um conjunto com mais de 280 mil registros e fraudes representando menos de 0,2% das amostras, configurando um cen√°rio realista de classifica√ß√£o assim√©trica que permite avaliar a robustez dos modelos.
* Reprodutibilidade: por ser p√∫blico e amplamente utilizado em pesquisas e competi√ß√µes, o acesso via Kaggle API garante que os experimentos possam ser reproduzidos de forma padronizada.

Al√©m disso, a base passou por um pr√©-processamento utilizando An√°lise de Componentes Principais (PCA), que resultou nas vari√°veis V1‚ÄìV28. Essa etapa reduz a dimensionalidade, preserva a privacidade dos dados e gera atributos ortogonais com boa separabilidade estat√≠stica, influenciando diretamente nas decis√µes de modelagem adotadas nas fases subsequentes do projeto.

## üß† Hip√≥tese
Transa√ß√µes fraudulentas apresentam padr√µes estat√≠sticos e num√©ricos distintos em rela√ß√£o √†s transa√ß√µes leg√≠timas, o que possibilita que algoritmos supervisionados aprendam a diferenciar esses dois grupos com boa capacidade de generaliza√ß√£o.

A hip√≥tese central do projeto √© que, ao combinar m√©tricas adequadas (como F1-score e ROC-AUC), t√©cnicas de balanceamento de dados (como SMOTE) e ajuste do threshold de decis√£o, √© poss√≠vel obter um modelo com alto recall para a classe minorit√°ria, preservando uma precis√£o satisfat√≥ria.

Para estabelecer um baseline interpret√°vel, foi utilizada Regress√£o Log√≠stica, um modelo linear simples e amplamente empregado em problemas de classifica√ß√£o bin√°ria. Al√©m de permitir avaliar a separabilidade linear entre as classes, esse modelo serve como refer√™ncia inicial para comparar m√©todos mais sofisticados.

Em seguida, foi testado o modelo Random Forest, escolhido por sua robustez, capacidade de capturar rela√ß√µes n√£o lineares e bom desempenho em cen√°rios complexos. Entre suas principais vantagens neste contexto, destacam-se:
* Resist√™ncia natural a ru√≠dos e outliers;
* Bom desempenho com dados desbalanceados, especialmente quando combinado com t√©cnicas de oversampling e ajuste de threshold;
* Alta flexibilidade, com possibilidade de ajuste fino via hiperpar√¢metros e fornecimento de probabilidades calibradas para otimiza√ß√£o do ponto de corte.

## 1) Configura√ß√£o Inicial e Instala√ß√£o de Pacotes
Nesta etapa foram instaladas e importadas todas as bibliotecas necess√°rias:

* kaggle ‚Äî para download automatizado do dataset
* pandas/numpy/seaborn/matplotlib ‚Äî para manipula√ß√£o e an√°lise explorat√≥ria
* scikit-learn ‚Äî para modelagem e m√©tricas
* imbalanced-learn ‚Äî para balanceamento com SMOTE.

```python
!pip -q install kaggle imbalanced-learn

import os, json, pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, recall_score, f1_score, roc_auc_score,
                             classification_report, confusion_matrix, roc_curve, auc,
                             precision_recall_curve)
from imblearn.over_sampling import SMOTE
import joblib
```

## 2) üì• Download do Dataset via Kaggle

As credenciais da conta Kaggle foram configuradas diretamente no ambiente Colab, e o dataset foi baixado e descompactado automaticamente.
O arquivo CSV foi lido com pandas e apresentou 284.807 linhas e 31 colunas, sem valores ausentes.

```python
DATASET_SLUG = "mlg-ulb/creditcardfraud"
df = pd.read_csv("creditcard.csv")
print(df.shape)
```

## 3) üìä An√°lise Explorat√≥ria dos Dados (EDA)
A etapa inicial de an√°lise explorat√≥ria de dados (EDA) teve como objetivo compreender a estrutura e as principais caracter√≠sticas do dataset antes da etapa de modelagem. Primeiramente, verificou-se que n√£o havia valores ausentes em nenhuma das 31 colunas, o que eliminou a necessidade de estrat√©gias de imputa√ß√£o ou limpeza complexa. Al√©m disso, observou-se que as vari√°veis V1 a V28 j√° se encontram padronizadas, resultado de uma transforma√ß√£o pr√©via por An√°lise de Componentes Principais (PCA), t√©cnica comumente utilizada para anonimizar dados de cart√£o de cr√©dito e, ao mesmo tempo, reduzir dimensionalidade preservando informa√ß√µes relevantes para detec√ß√£o de padr√µes.

O histograma do Amount evidenciou uma distribui√ß√£o altamente assim√©trica, indicando que poucas transa√ß√µes concentram valores muito altos. Essa caracter√≠stica justificou a aplica√ß√£o de uma transforma√ß√£o logar√≠tmica log(Amount + 1), que suavizou a cauda longa e permitiu uma visualiza√ß√£o mais clara da distribui√ß√£o.

A matriz de correla√ß√£o foi utilizada para avaliar poss√≠veis multicolinearidades entre as vari√°veis ‚Äî as componentes PCA apresentaram correla√ß√µes relativamente baixas e bem distribu√≠das, indicando aus√™ncia de colinearidade excessiva.

Por fim, a an√°lise da vari√°vel alvo Class mostrou um desbalanceamento extremo entre classes, evidenciando a necessidade de t√©cnicas espec√≠ficas de balanceamento para evitar que modelos enviesem predi√ß√µes para a classe majorit√°ria.

Gr√°ficos utilizados:
* Histograma de Amount
* Histograma de log(Amount+1)
* Matriz de correla√ß√£o

## 4) ‚úÇÔ∏è Divis√£o Treino/Teste (Stratified)

Os dados foram divididos em 80% treino e 20% teste, preservando a propor√ß√£o das classes (stratify=y). Essa escolha garante representatividade da classe fraudulenta em ambos os conjuntos, evitando problemas de vi√©s no treinamento ou avalia√ß√£o.

## 5) üß™ Modelagem Inicial ‚Äî Baseline, Logistic Regression e Random Forest
Para estabelecer um ponto de partida comparativo, foram treinados tr√™s modelos:
Baseline com DummyClassifier:
* Accuracy ‚âà 0.998
* Recall = 0 (n√£o detectou nenhuma fraude).

Logistic Regression (com class_weight='balanced'):
* Recall alto, por√©m precis√£o baixa.

Random Forest:
* Melhor equil√≠brio entre precis√£o e recall.
* F1-score muito superior ao baseline.
Essa etapa inicial confirmou que m√©tricas de acur√°cia isoladas s√£o enganosas em cen√°rios desbalanceados e que modelos mais robustos, como Random Forest, oferecem desempenho mais consistente.

## 6) üìà Verifica√ß√£o de Overfitting e Underfitting
As acur√°cias no treino e teste foram praticamente iguais para Random Forest, indicando boa generaliza√ß√£o.
```python
Acur√°cia Treino: 1.0000  
Acur√°cia Teste:  0.9995
```
Overfitting e underfitting foram verificados comparando as m√©tricas entre treino e teste e pela estabilidade na valida√ß√£o cruzada. Como as acur√°cias foram muito pr√≥ximas e n√£o houve degrada√ß√£o severa de m√©tricas, n√£o h√° sinais de overfitting. A aus√™ncia de underfitting indica que a capacidade do modelo foi suficiente para aprender padr√µes relevantes sem ficar limitada.

## 7) üîπ Valida√ß√£o Cruzada (3 folds)
Foi aplicada valida√ß√£o cruzada estratificada com 3 folds para avaliar a consist√™ncia das m√©tricas entre diferentes parti√ß√µes do conjunto de dados.
A estratifica√ß√£o garante que cada fold mantenha a propor√ß√£o original das classes, fundamental em cen√°rios desbalanceados. A escolha de 3 folds foi feita para equilibrar robustez com custo computacional.

O desvio padr√£o reduzido dos F1-scores do Random Forest indicou boa estabilidade e baixa variabilidade, refor√ßando a confiabilidade do modelo.

```python
from sklearn.model_selection import StratifiedKFold, cross_val_score

cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
scores_log = cross_val_score(pipe_log, X_train, y_train, cv=cv, scoring='f1')
scores_rf = cross_val_score(pipe_rf, X_train, y_train, cv=cv, scoring='f1')
```
## 8) üß≠ Ajuste de Hiperpar√¢metros ‚Äî GridSearchCV
Em seguida, foi realizada a etapa de ajuste de hiperpar√¢metros por meio do GridSearchCV, utilizando tamb√©m valida√ß√£o cruzada. O objetivo foi buscar a melhor combina√ß√£o entre os par√¢metros n_estimators (50 e 100) e max_depth (10 e None). Essa etapa permitiu encontrar um modelo Random Forest otimizado, que manteve alto desempenho no conjunto de teste, equilibrando capacidade de detec√ß√£o de fraudes e generaliza√ß√£o.
```python
param_grid = {
    'clf__n_estimators': [50, 100],
    'clf__max_depth': [10, None]
}

grid = GridSearchCV(pipe_rf, param_grid=param_grid, cv=3, scoring='f1', n_jobs=-1)
grid.fit(X_train_sample, y_train_sample)
best_model = grid.best_estimator_
```

## 9) üìâ Avalia√ß√£o do Modelo Otimizado
Ap√≥s a otimiza√ß√£o, foi feita a avalia√ß√£o detalhada do modelo ajustado. As m√©tricas de desempenho mostraram Acur√°cia ‚âà 0.9990, F1-score ‚âà 0.6093 e ROC-AUC ‚âà 0.9428, valores bastante altos, mas ainda com espa√ßo para melhoria no recall da classe minorit√°ria. Foram geradas duas visualiza√ß√µes essenciais para interpreta√ß√£o do modelo: a matriz de confus√£o, que evidencia a propor√ß√£o de acertos e erros entre as classes, e a curva ROC, que ilustra a rela√ß√£o entre taxa de verdadeiros positivos e falsos positivos.

Para lidar mais diretamente com o forte desbalanceamento da vari√°vel alvo, foi introduzida a primeira estrat√©gia de melhoria: rebalanceamento com SMOTE (Synthetic Minority Over-sampling Technique). Essa t√©cnica gera novas amostras sint√©ticas da classe minorit√°ria, equilibrando a distribui√ß√£o de classes no conjunto de treino.
```python
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)
```

## 10) üÜï Melhoria 1 ‚Äî Balanceamento com SMOTE
O SMOTE (Synthetic Minority Over-sampling Technique) foi aplicado no conjunto de treino para lidar com o desbalanceamento de classes.
O SMOTE foi escolhido em vez de t√©cnicas de undersampling porque mant√©m a diversidade da classe majorit√°ria, permitindo melhor generaliza√ß√£o.
```python
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)
```
O modelo Random Forest reentreinado apresentou F1-score mais alto e maior recall, confirmando a efetividade do balanceamento.

## 11) üÜï Melhoria 2 ‚Äî Ajuste de Threshold de Decis√£o
A segunda melhoria aplicada foi o ajuste do limiar de decis√£o (threshold). O threshold padr√£o de 0.5 foi substitu√≠do por um valor √≥timo determinado a partir da maximiza√ß√£o do F1-score na curva Precision-Recall, permitindo um controle mais fino sobre a taxa de verdadeiros positivos e falsos positivos.
Essa abordagem aumentou significativamente a sensibilidade do modelo, reduzindo falsos negativos e melhorando o equil√≠brio entre precis√£o e recall ‚Äî dois indicadores cr√≠ticos em problemas de detec√ß√£o de fraude.

## 12) üìä Compara√ß√£o de Modelos
Com todas as etapas de modelagem conclu√≠das, foi realizada uma compara√ß√£o consolidada entre os modelos. Os resultados evidenciaram que a acur√°cia isolada pode ser enganosa, pois at√© mesmo um classificador que sempre prediz a classe majorit√°ria obt√©m valores elevados nessa m√©trica. Em contrapartida, m√©tricas mais adequadas para cen√°rios desbalanceados, como F1-score e ROC-AUC, mostraram que o uso combinado de SMOTE e ajuste de threshold foi decisivo para elevar o desempenho dos modelos, sobretudo na detec√ß√£o da classe minorit√°ria (fraude).

Ap√≥s todas as etapas de experimenta√ß√£o e otimiza√ß√£o, o modelo com melhor performance foi a Random Forest otimizada via GridSearchCV, combinada com as estrat√©gias de rebalanceamento com SMOTE e ajuste de threshold.

Essa solu√ß√£o destacou-se por:
* Alcan√ßar alta capacidade de detec√ß√£o de fraudes, apresentando recall e F1-score significativamente superiores aos demais modelos;
* Demonstrar boa capacidade de generaliza√ß√£o, com m√©tricas consistentes entre treino e teste e baixa vari√¢ncia na valida√ß√£o cruzada;
* Oferecer robustez pr√°tica, refletida em um ROC-AUC elevado e estabilidade mesmo diante de forte desbalanceamento de classes.

Assim, o modelo final atende plenamente ao objetivo central do projeto: maximizar a detec√ß√£o de fraudes com o menor n√∫mero poss√≠vel de falsos negativos, preservando ao mesmo tempo uma boa precis√£o global.

## 13) üìä An√°lise do Desbalanceamento
A an√°lise do desbalanceamento foi complementada com um gr√°fico de barras, que ilustrou visualmente a disparidade extrema entre as classes ‚ÄúN√£o Fraude‚Äù e ‚ÄúFraude‚Äù. Essa etapa refor√ßou a import√¢ncia das t√©cnicas de balanceamento aplicadas para que o modelo conseguisse aprender padr√µes da minoria de forma eficaz.

## 14) üìù Resumo T√©cnico Final
* Dataset altamente desbalanceado.
* M√©tricas principais: F1-score e ROC-AUC.
* T√©cnicas aplicadas: valida√ß√£o cruzada, GridSearchCV, SMOTE e ajuste de threshold.
* Import√¢ncia das features foi avaliada, e todas foram mantidas, pois contribu√≠ram de forma complementar.
* Melhor modelo: Random Forest otimizado + SMOTE + threshold tuning.
* O modelo apresentou bom desempenho geral, estabilidade entre treino/teste e baixo risco de overfitting.

A escolha dessa combina√ß√£o se justifica por oferecer o melhor equil√≠brio entre recall e precis√£o, fundamental em cen√°rios de fraude.

## 15) üíæ Salvamento do Modelo Final
Por fim, o modelo final foi salvo em arquivo .pkl para uso posterior ou integra√ß√£o em um pipeline de produ√ß√£o:
```python
import joblib
joblib.dump(best_model, 'best_model_creditcard_rf.pkl')
```

Como pr√≥ximos passos recomendados, sugere-se explorar modelos mais avan√ßados, como XGBoost e LightGBM, realizar calibra√ß√£o de probabilidades para melhor interpreta√ß√£o dos scores, implementar monitoramento de drift e explicabilidade (por exemplo, com SHAP ou LIME) e, futuramente, desenvolver um dashboard em tempo real para acompanhamento cont√≠nuo da performance do modelo em produ√ß√£o.




